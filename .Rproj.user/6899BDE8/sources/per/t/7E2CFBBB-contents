---
title: "r_sample"
author: "Michael D Evans"
date: "5/6/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr) 
library(comprehenr)
```

R sample code
By Michael D. Evans
  In this sample, I generate some **simulated data** for a study where participants complete some surveys and play a game that measures risk assesment (game link below!). Participants will be in two groups, a  treatment group ("group1") and a no-treatment group ("group2").
  
  The hypotheses I am testing are whether participants in the treatment group are more accurately able to assess risk, whether there are differences in survey responses for the groups, and which items from the surveys are most strongly associated with performance.

Survey1: five facet mindfulness questionnaire (39 items)
Survey2: Barret impulsivity scale (30 items)
    
Behavioral Task: Ice Cream Game (try it out: www.mdevans.me/projects/icecream; adapted from BART task, Lejuez et al. 2002 http://www.impulsivity.org/measurement/BART)
    Your goal in the Ice Cream Game is to sell as much ice cream using as few cones as possible (e.g. sell as many scoops of ice cream as possible for each trial). Each scoop increases the reward value +1. At any point (even the first scoop), the ice cream can fall, and you cannot sell any- you receive 0 points and move onto the next trial. The risk of the scoops falling increases with each additional scoop, with it guranteed to fall by the 64th scoop (1/64 probability on the first scoop, 32/64 on the 32nd scoop, etc.). Optimal behavior would be to sell the ice cream when the probability of failure is as close to 50% as possible, in this case, at 32 scoops. Fewer scoops results in missing out on probable reward, and more scoops results in unneccesary risk.
    
Participants:
Group1 (treatment): 100 adults, 18-55
Group2 (control):100 adults, 18-55

Hypotheses:
Hyp1: group1 will show greater task learning and risk appraisal demonstrated with scores non-significantly different from optimal performance (32/64 = .5); group2 will show detrimental risk aversion demonstrated with scores signficantly below optimal.<br>
Hyp2: group1 performance scores will be statistically different (greater) than group2<br>
Hyp3: group1 will be statistically different from group2 in all questionnaires as following: higher for FFMQ, lower for BIS, lower for PTQ.

```{r set the stage}
n<-200 # set TOTAL number of subjects
n_groups<-2 # number of groups, subject numbers randomly assigned
participants <- sample.int(1e3, n) #assign random subject ids 1-1000
group1 <- participants[1:(n/2)] # first half to group1
group2 <- participants[((n/2)+1):n] # second half to group2
length(group1)==length(group2) && length(group1)==(n/2) # check lengths match up

# create main data table, populate some fields
# columns: subj, group, age, gender, ffmq1, ffmq2...bis1, bis2...ic_risk, ic_total, ic_mean, ic_rt 
df <- data.frame(
  id = c(group1,group2), # combine participants (could also just use participants)
  group = c(rep(1,(n/2)),rep(2,(n/2))), # assign group number
  age = runif(n,18,55) # generate ages, random sample uniform dist range 18-55
)

# other fields require more nuanced distributions

# gender
# we'll sample gender from categorical dist (.49male, .49female, .2non-binary/other)
# well use random uni dist 0-1, 0-.49 = m, .49-.98 = f, >=.98 = nb
# since we're using random numbers, our sample may not perfectly reflect our simulated population e.g. may have 0 non-binary individuals
m<-0.49 # e.g 49%
f<-0.49
nb<-1-m-f # remainder *note rule: m+f<=1
gender = runif(n) # generate n-number values 0-1 random uniform dist.

for (ii in 1:n){ # counter to go through each gender item
  if (gender[ii]<m){ # if value below male threshold
    gender[ii]<-'m'
    next # skip to next counter item otherwise value overwritten
  }else if (gender[ii]<m+f){ # if value greater than male,but less than male+female
    gender[ii]<-'f'
    next
  }else{ # <= m+f
    gender[ii]<-'nb'
  }
}
df$gender = gender # add to our dataframe

#ice cream game
# since we are simulating data, let's simulate are hypotheses are true
# so..
# group1 we'll random sample from a norm dist. m=0.5 sd=0.08
# group2 random norm m=0.3 sd=0.15
m_g1 =32 # mean, group 1
sd_g1 = 2.4 # sd, group 1
m_g2 = 21.6
sd_g2 = 3.2
df$ic_scoops = c(rnorm((n/2),m_g1,sd_g1),rnorm((n/2),m_g2,sd_g2)) # normal dist, add to df
plt<-ggplot(data=df, aes=(x=ic_scoops))+ # plot as histogram to check distributions
  geom_histogram(mapping=aes(x=ic_scoops, fill=as.factor(group)),binwidth=3)
print(plt) # display plot

# any reason to think reaction times would be different between groups?
# if not, just assign from norm. dist w reasonable time (fast game, so expect low rt)
m_rt<-400 
sd_rt<-50
df$ic_rt = rnorm(n,m_rt,sd_rt) # normal dist., add to dataframe
plt<-ggplot(data=df)+
  geom_histogram(mapping=aes(x=ic_rt,fill=as.factor(group)),binwidth=50)
print(plt)
df
```


```{r}
## survey data
# first survey is five facet mindfulness questionnaire, 39 items w 5 factors 

# we hypothesized that treatment (group1) would score higher than control (group2), so we'll set anchors for those as well. 
# item responses range 1-5
m_ffmq_g1 <- 3.5 # mean ffmq score for group1
sd_ffmq_g1 <- 1 # sd ffmq score, group1

m_ffmq_g2 <- 2.5
sd_ffmq_g2 <- 1

# we'll generate data such that a factor analysis should reveal the factors by setting different anchors for each factor, and generative values for associated questions from those anchors
# factor: factor_name(factor_items)
# factor1: observing (1, 6, 11, 15, 20, 26, 31, 36)
obs_items = c(1,6,11,15,20,26,31,36) # we'll use later when generating data matrices
# factor2: describing (2, 7, 12R, 16R, 22R, 27, 32, 37) R = reverse scoring, can subtract upper limit to score (e.g 6; response:1, score:6-1=5)
desc_items = c(2,7,12,16,22,27,32,37)
# factor3: awareness (5R, 8R, 13R, 18R, 23R, 28R, 34R, 38R)
aware_items = c(5,8,13,18,23,28,34,38)
# factor4: nonjudging (3R, 10R, 14R, 17R, 25R, 30R, 35R, 39R)
nj_items = c(3,10,14,17,25,30,35,39)
# factor5: nonreactivity (4, 9, 19, 21, 24, 29, 33)
nr_items = c(4,9,19,21,24,29,33)

# preallocate matrix for score
ffmq <- matrix(data=NA,nrow=n,ncol=39) # 39 survey items

minMax <- function(m,floor=1,ceiling=5){
# function to set floor and ceiling values in a matrix
  m[m<floor]<-floor # set any values less than floor to floor
  m[m>ceiling]<-ceiling # same for ceiling
  return(m)
}

removeItems <- function(m,factor_items){
# function to remove non-factor items from matrix
  m_vec <- to_vec(for(i in 1:39) # create vector for item placement,
    if(i %in% factor_items) 1 else 0)  # 1s in question index associated w factor, else NA
  
  for (ii in 1:length(m_vec)){ # go through binary vector representing factor items
    m[,ii]<-m[,ii]*m_vec[ii] #  if 0, drop column, if 1, keep column as is
  }
  return(m)
}

gen_factor_data <-function(factor_items,print_plot=FALSE){
# function to generate ffmq factor data
# input: factor indicies
# output: 200x39 matrix of factor item responses (non-factor filled w 0s)
#   rows 1:100: group1
#   rows 101:200: group2
  m <- c(rnorm(length(group1),m_ffmq_g1,sd_ffmq_g1), # generate mean factor score for group1
           rnorm(length(group2),m_ffmq_g2,sd_ffmq_g2)) # and group2
  m = matrix(rnorm(39*n,m,1),n,39) # generate matrix using random means (static per participant) 
  
  # using this method, we'll get some float values instead of integer
  mode(m)<-'integer' # set internal storage mode to integer (truncates)
  
  # we'll also run into values outside our range of 1-5
  m<-minMax(m)
  
  # good time to print some histograms to make sure distribution is as-expects
  if(print_plot==TRUE){
    hist(m[1:100,]) # first 100 rows e.g group1
    abline(v=m_ffmq_g1,col='red') # plot group1 population mean
    
    hist(obs[101:200,])# group2
    abline(v=m_ffmq_g2,col='red')
  }
  
  # get rid of non-factor columns
  m<-removeItems(m,factor_items)
  
  # my sample is slightly lower than defined means - due to changing data type to int instead of rounding, but overall looks good!
  # remove non-factor items
  return(m)
}

# generate factor item responses
obs <- gen_factor_data(obs_items)
desc <- gen_factor_data(desc_items)
aware <- gen_factor_data(aware_items)
njudge <- gen_factor_data(nj_items)
nreact <- gen_factor_data(nr_items)

# as is, all factors have the same means since they were generated w same population values
# let's assume some variability between factors, and for fun, say that the treatment
# works particularly well for non-judgement and non-react

obs<-obs-1 # lower all obs scores by 1
obs<-minMax(obs) # reset floor/ceiling
obs<-removeItems(obs,obs_items) # 1 added to 0 values, remove non-factor columns

njudge[1:100,]<-njudge[1:100,]+1 # increase treatment group non-judge by 1
njudge<-minMax(njudge)
njudge<-removeItems(njudge,nj_items)

nreact[1:100,]<-nreact[1:100,]+1 # increase tx group nreact 
nreact<-minMax(nreact)
nreact<-removeItems(nreact,nr_items)

aware[101:200,]<-aware[101:200,]+1 # increase control group aware (now ~= to tx group)
aware<-minMax(aware)
aware<-removeItems(aware,aware_items)

desc[101:200,]<-desc[101:200,]+1 # increast ctrl group desc (now ~= to tx group)
desc<-minMax(desc)
desc<-removeItems(desc,desc_items)
# since we counter-balanced updating values, overall mean for groups should be the same

ffmq = data.frame(obs+desc+aware+njudge+nreact) # combine to create final ffmq data frame
```

## Including Plots

You can also embed plots, for example:

```{r function}



obs2 <- gen_factor_data(obs_items)

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
